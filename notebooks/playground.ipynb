{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Playground\n",
    "\n",
    "Interactive notebook for testing and refining prompts with Claude using the Anthropic SDK.\n",
    "\n",
    "## Features\n",
    "- Single prompt testing with parameter controls\n",
    "- Batch testing for multiple inputs\n",
    "- A/B testing for prompt comparison\n",
    "- Template management\n",
    "- Response analysis and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration\n",
    "\n",
    "Import libraries, load API key, and initialize the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "import pandas as pd\n",
    "\n",
    "from prompt_playground.client import create_client, send_prompt, send_batch, count_tokens, estimate_cost\n",
    "from prompt_playground.prompts import PromptTemplate, PromptLibrary, validate_prompt\n",
    "from prompt_playground.analysis import calculate_metrics, compare_responses, visualize_comparison, extract_key_points, analyze_tone\n",
    "\n",
    "load_dotenv()\n",
    "console = Console()\n",
    "\n",
    "rprint(\"[green]✓[/green] Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    client = create_client()\n",
    "    rprint(\"[green]✓[/green] Anthropic client initialized\")\n",
    "except ValueError as e:\n",
    "    rprint(f\"[red]✗[/red] {e}\")\n",
    "    rprint(\"[yellow]![/yellow] Please set ANTHROPIC_API_KEY in your .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selector = widgets.Dropdown(\n",
    "    options=[\n",
    "        'claude-sonnet-4-5-20250929',\n",
    "        'claude-opus-4-5-20251101',\n",
    "        'claude-3-7-sonnet-20250219',\n",
    "        'claude-3-5-haiku-20241022',\n",
    "    ],\n",
    "    value='claude-sonnet-4-5-20250929',\n",
    "    description='Model:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "temperature_slider = widgets.FloatSlider(\n",
    "    value=1.0,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description='Temperature:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "max_tokens_slider = widgets.IntSlider(\n",
    "    value=4096,\n",
    "    min=256,\n",
    "    max=8192,\n",
    "    step=256,\n",
    "    description='Max Tokens:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Model Configuration</h3>\"),\n",
    "    model_selector,\n",
    "    temperature_slider,\n",
    "    max_tokens_slider\n",
    "]))\n",
    "\n",
    "session_responses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Single Prompt Testing\n",
    "\n",
    "Test individual prompts with full parameter control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter your prompt here...',\n",
    "    description='Prompt:',\n",
    "    layout=widgets.Layout(width='100%', height='120px'),\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "system_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Optional system prompt...',\n",
    "    description='System:',\n",
    "    layout=widgets.Layout(width='100%', height='80px'),\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "execute_button = widgets.Button(\n",
    "    description='Execute Prompt',\n",
    "    button_style='primary',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_execute_click(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        \n",
    "        prompt = prompt_input.value\n",
    "        system = system_input.value if system_input.value else None\n",
    "        \n",
    "        if not prompt:\n",
    "            rprint(\"[red]Please enter a prompt[/red]\")\n",
    "            return\n",
    "        \n",
    "        validation = validate_prompt(prompt)\n",
    "        if not validation['valid']:\n",
    "            rprint(f\"[yellow]Warning:[/yellow] {', '.join(validation['issues'])}\")\n",
    "        \n",
    "        rprint(\"[blue]Sending prompt...[/blue]\")\n",
    "        \n",
    "        try:\n",
    "            response = send_prompt(\n",
    "                prompt=prompt,\n",
    "                model=model_selector.value,\n",
    "                system=system,\n",
    "                temperature=temperature_slider.value,\n",
    "                max_tokens=max_tokens_slider.value,\n",
    "                client=client\n",
    "            )\n",
    "            \n",
    "            session_responses.append(response)\n",
    "            \n",
    "            rprint(Panel(response['text'], title=\"[bold green]Response[/bold green]\", expand=False))\n",
    "            \n",
    "            metrics = calculate_metrics(response)\n",
    "            \n",
    "            table = Table(title=\"Response Metrics\")\n",
    "            table.add_column(\"Metric\", style=\"cyan\")\n",
    "            table.add_column(\"Value\", style=\"green\")\n",
    "            \n",
    "            table.add_row(\"Model\", response['model'])\n",
    "            table.add_row(\"Words\", str(metrics['word_count']))\n",
    "            table.add_row(\"Characters\", str(metrics['char_count']))\n",
    "            table.add_row(\"Input Tokens\", str(metrics['input_tokens']))\n",
    "            table.add_row(\"Output Tokens\", str(metrics['output_tokens']))\n",
    "            table.add_row(\"Total Tokens\", str(metrics['total_tokens']))\n",
    "            table.add_row(\"Estimated Cost\", f\"${metrics['estimated_cost']:.6f}\")\n",
    "            table.add_row(\"Sentences\", str(metrics['sentence_count']))\n",
    "            table.add_row(\"Paragraphs\", str(metrics['paragraph_count']))\n",
    "            \n",
    "            console.print(table)\n",
    "            \n",
    "        except Exception as e:\n",
    "            rprint(f\"[red]Error:[/red] {str(e)}\")\n",
    "\n",
    "execute_button.on_click(on_execute_click)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Single Prompt Testing</h3>\"),\n",
    "    prompt_input,\n",
    "    system_input,\n",
    "    execute_button,\n",
    "    output_area\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Testing\n",
    "\n",
    "Test multiple inputs with the same prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prompts_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter prompts, one per line...',\n",
    "    description='Prompts:',\n",
    "    layout=widgets.Layout(width='100%', height='150px'),\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "batch_execute_button = widgets.Button(\n",
    "    description='Execute Batch',\n",
    "    button_style='success',\n",
    "    icon='list'\n",
    ")\n",
    "\n",
    "batch_output = widgets.Output()\n",
    "\n",
    "def on_batch_execute(b):\n",
    "    with batch_output:\n",
    "        batch_output.clear_output()\n",
    "        \n",
    "        prompts_text = batch_prompts_input.value\n",
    "        if not prompts_text:\n",
    "            rprint(\"[red]Please enter at least one prompt[/red]\")\n",
    "            return\n",
    "        \n",
    "        prompts = [p.strip() for p in prompts_text.split('\\n') if p.strip()]\n",
    "        \n",
    "        rprint(f\"[blue]Executing {len(prompts)} prompts...[/blue]\")\n",
    "        \n",
    "        try:\n",
    "            responses = send_batch(\n",
    "                prompts=prompts,\n",
    "                model=model_selector.value,\n",
    "                temperature=temperature_slider.value,\n",
    "                max_tokens=max_tokens_slider.value,\n",
    "                client=client\n",
    "            )\n",
    "            \n",
    "            session_responses.extend(responses)\n",
    "            \n",
    "            df = compare_responses(responses)\n",
    "            \n",
    "            display(HTML(df[['response_id', 'word_count', 'output_tokens', 'estimated_cost']].to_html()))\n",
    "            \n",
    "            rprint(\"\\n[bold]Responses:[/bold]\")\n",
    "            for idx, response in enumerate(responses):\n",
    "                rprint(Panel(\n",
    "                    response['text'][:200] + ('...' if len(response['text']) > 200 else ''),\n",
    "                    title=f\"[bold]Response {idx + 1}[/bold]\",\n",
    "                    expand=False\n",
    "                ))\n",
    "            \n",
    "            total_cost = sum(r['estimated_cost'] for r in df.to_dict('records'))\n",
    "            rprint(f\"\\n[green]Total Cost:[/green] ${total_cost:.6f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            rprint(f\"[red]Error:[/red] {str(e)}\")\n",
    "\n",
    "batch_execute_button.on_click(on_batch_execute)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Batch Testing</h3>\"),\n",
    "    batch_prompts_input,\n",
    "    batch_execute_button,\n",
    "    batch_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A/B Testing\n",
    "\n",
    "Compare multiple prompt variants with the same input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter the common input/question...',\n",
    "    description='Input:',\n",
    "    layout=widgets.Layout(width='100%', height='80px'),\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "variant_a = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Prompt variant A (use {input} for substitution)...',\n",
    "    description='Variant A:',\n",
    "    layout=widgets.Layout(width='100%', height='80px'),\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "variant_b = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Prompt variant B (use {input} for substitution)...',\n",
    "    description='Variant B:',\n",
    "    layout=widgets.Layout(width='100%', height='80px'),\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "ab_execute_button = widgets.Button(\n",
    "    description='Run A/B Test',\n",
    "    button_style='warning',\n",
    "    icon='columns'\n",
    ")\n",
    "\n",
    "ab_output = widgets.Output()\n",
    "\n",
    "def on_ab_execute(b):\n",
    "    with ab_output:\n",
    "        ab_output.clear_output()\n",
    "        \n",
    "        input_text = ab_input.value\n",
    "        variants = [variant_a.value, variant_b.value]\n",
    "        variants = [v for v in variants if v.strip()]\n",
    "        \n",
    "        if not input_text:\n",
    "            rprint(\"[red]Please enter input text[/red]\")\n",
    "            return\n",
    "        \n",
    "        if len(variants) < 2:\n",
    "            rprint(\"[red]Please enter at least 2 variants[/red]\")\n",
    "            return\n",
    "        \n",
    "        prompts = [v.format(input=input_text) for v in variants]\n",
    "        \n",
    "        rprint(f\"[blue]Testing {len(prompts)} variants...[/blue]\")\n",
    "        \n",
    "        try:\n",
    "            responses = send_batch(\n",
    "                prompts=prompts,\n",
    "                model=model_selector.value,\n",
    "                temperature=temperature_slider.value,\n",
    "                max_tokens=max_tokens_slider.value,\n",
    "                client=client\n",
    "            )\n",
    "            \n",
    "            session_responses.extend(responses)\n",
    "            \n",
    "            df = compare_responses(responses)\n",
    "            display(HTML(df.to_html()))\n",
    "            \n",
    "            rprint(\"\\n[bold]Side-by-Side Comparison:[/bold]\\n\")\n",
    "            \n",
    "            for idx, response in enumerate(responses):\n",
    "                variant_letter = chr(65 + idx)\n",
    "                rprint(Panel(\n",
    "                    response['text'],\n",
    "                    title=f\"[bold cyan]Variant {variant_letter}[/bold cyan]\",\n",
    "                    expand=False\n",
    "                ))\n",
    "                \n",
    "                tone = analyze_tone(response['text'])\n",
    "                rprint(f\"  Tone: {tone['formality']}, Complexity: {tone['complexity']}, Perspective: {tone['perspective']}\\n\")\n",
    "            \n",
    "            import matplotlib.pyplot as plt\n",
    "            fig = visualize_comparison(responses, metric='tokens')\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            rprint(f\"[red]Error:[/red] {str(e)}\")\n",
    "\n",
    "ab_execute_button.on_click(on_ab_execute)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>A/B Testing</h3>\"),\n",
    "    ab_input,\n",
    "    variant_a,\n",
    "    variant_b,\n",
    "    ab_execute_button,\n",
    "    ab_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompt Templates\n",
    "\n",
    "Manage and use prompt templates with variable substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = PromptLibrary('prompt_templates.json')\n",
    "\n",
    "template_name_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Template name...',\n",
    "    description='Name:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "template_text_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Template with {variables} in curly braces...',\n",
    "    description='Template:',\n",
    "    layout=widgets.Layout(width='100%', height='100px'),\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "template_vars_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='variable1, variable2, ...',\n",
    "    description='Variables:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "save_template_button = widgets.Button(\n",
    "    description='Save Template',\n",
    "    button_style='info',\n",
    "    icon='save'\n",
    ")\n",
    "\n",
    "list_templates_button = widgets.Button(\n",
    "    description='List Templates',\n",
    "    button_style='info',\n",
    "    icon='list'\n",
    ")\n",
    "\n",
    "template_output = widgets.Output()\n",
    "\n",
    "def on_save_template(b):\n",
    "    with template_output:\n",
    "        template_output.clear_output()\n",
    "        \n",
    "        name = template_name_input.value\n",
    "        text = template_text_input.value\n",
    "        vars_text = template_vars_input.value\n",
    "        \n",
    "        if not name or not text or not vars_text:\n",
    "            rprint(\"[red]Please fill all fields[/red]\")\n",
    "            return\n",
    "        \n",
    "        variables = [v.strip() for v in vars_text.split(',')]\n",
    "        \n",
    "        template = PromptTemplate(text, variables)\n",
    "        \n",
    "        if not template.validate():\n",
    "            rprint(\"[yellow]Warning:[/yellow] Template variables don't match the template text\")\n",
    "        \n",
    "        library.save(name, template)\n",
    "        rprint(f\"[green]✓[/green] Template '{name}' saved successfully\")\n",
    "\n",
    "def on_list_templates(b):\n",
    "    with template_output:\n",
    "        template_output.clear_output()\n",
    "        \n",
    "        templates = library.list_all()\n",
    "        \n",
    "        if not templates:\n",
    "            rprint(\"[yellow]No templates saved yet[/yellow]\")\n",
    "            return\n",
    "        \n",
    "        table = Table(title=\"Saved Templates\")\n",
    "        table.add_column(\"Name\", style=\"cyan\")\n",
    "        table.add_column(\"Variables\", style=\"green\")\n",
    "        \n",
    "        for name in templates:\n",
    "            template = library.load(name)\n",
    "            table.add_row(name, ', '.join(template.variables))\n",
    "        \n",
    "        console.print(table)\n",
    "\n",
    "save_template_button.on_click(on_save_template)\n",
    "list_templates_button.on_click(on_list_templates)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Prompt Templates</h3>\"),\n",
    "    template_name_input,\n",
    "    template_text_input,\n",
    "    template_vars_input,\n",
    "    widgets.HBox([save_template_button, list_templates_button]),\n",
    "    template_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_template_dropdown = widgets.Dropdown(\n",
    "    options=library.list_all(),\n",
    "    description='Load:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "refresh_dropdown_button = widgets.Button(\n",
    "    description='Refresh List',\n",
    "    button_style='',\n",
    "    icon='refresh'\n",
    ")\n",
    "\n",
    "fill_template_button = widgets.Button(\n",
    "    description='Load & Fill',\n",
    "    button_style='primary',\n",
    "    icon='edit'\n",
    ")\n",
    "\n",
    "template_fill_output = widgets.Output()\n",
    "\n",
    "def on_refresh_dropdown(b):\n",
    "    load_template_dropdown.options = library.list_all()\n",
    "\n",
    "def on_fill_template(b):\n",
    "    with template_fill_output:\n",
    "        template_fill_output.clear_output()\n",
    "        \n",
    "        if not load_template_dropdown.value:\n",
    "            rprint(\"[red]Please select a template[/red]\")\n",
    "            return\n",
    "        \n",
    "        template = library.load(load_template_dropdown.value)\n",
    "        \n",
    "        rprint(f\"[cyan]Template:[/cyan] {template.template}\")\n",
    "        rprint(f\"[cyan]Variables:[/cyan] {', '.join(template.variables)}\\n\")\n",
    "        \n",
    "        var_inputs = {}\n",
    "        for var in template.variables:\n",
    "            var_inputs[var] = widgets.Text(\n",
    "                description=f\"{var}:\",\n",
    "                style={'description_width': '100px'}\n",
    "            )\n",
    "        \n",
    "        test_button = widgets.Button(\n",
    "            description='Test Template',\n",
    "            button_style='success'\n",
    "        )\n",
    "        \n",
    "        result_output = widgets.Output()\n",
    "        \n",
    "        def on_test_template(b):\n",
    "            with result_output:\n",
    "                result_output.clear_output()\n",
    "                \n",
    "                values = {var: widget.value for var, widget in var_inputs.items()}\n",
    "                \n",
    "                try:\n",
    "                    filled = template.fill(**values)\n",
    "                    rprint(Panel(filled, title=\"[bold]Filled Prompt[/bold]\", expand=False))\n",
    "                    \n",
    "                    response = send_prompt(\n",
    "                        prompt=filled,\n",
    "                        model=model_selector.value,\n",
    "                        temperature=temperature_slider.value,\n",
    "                        max_tokens=max_tokens_slider.value,\n",
    "                        client=client\n",
    "                    )\n",
    "                    \n",
    "                    session_responses.append(response)\n",
    "                    \n",
    "                    rprint(Panel(response['text'], title=\"[bold green]Response[/bold green]\", expand=False))\n",
    "                    \n",
    "                    metrics = calculate_metrics(response)\n",
    "                    rprint(f\"\\n[cyan]Tokens:[/cyan] {metrics['total_tokens']} | [cyan]Cost:[/cyan] ${metrics['estimated_cost']:.6f}\")\n",
    "                    \n",
    "                except ValueError as e:\n",
    "                    rprint(f\"[red]Error:[/red] {str(e)}\")\n",
    "                except Exception as e:\n",
    "                    rprint(f\"[red]API Error:[/red] {str(e)}\")\n",
    "        \n",
    "        test_button.on_click(on_test_template)\n",
    "        \n",
    "        display(widgets.VBox([\n",
    "            widgets.HTML(\"<h4>Fill Template Variables</h4>\"),\n",
    "            *var_inputs.values(),\n",
    "            test_button,\n",
    "            result_output\n",
    "        ]))\n",
    "\n",
    "refresh_dropdown_button.on_click(on_refresh_dropdown)\n",
    "fill_template_button.on_click(on_fill_template)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Use Template</h3>\"),\n",
    "    widgets.HBox([load_template_dropdown, refresh_dropdown_button]),\n",
    "    fill_template_button,\n",
    "    template_fill_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Analysis\n",
    "\n",
    "Analyze and visualize session results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_button = widgets.Button(\n",
    "    description='Analyze Session',\n",
    "    button_style='success',\n",
    "    icon='chart-bar'\n",
    ")\n",
    "\n",
    "export_button = widgets.Button(\n",
    "    description='Export to CSV',\n",
    "    button_style='info',\n",
    "    icon='download'\n",
    ")\n",
    "\n",
    "clear_button = widgets.Button(\n",
    "    description='Clear Session',\n",
    "    button_style='danger',\n",
    "    icon='trash'\n",
    ")\n",
    "\n",
    "analysis_output = widgets.Output()\n",
    "\n",
    "def on_analyze(b):\n",
    "    with analysis_output:\n",
    "        analysis_output.clear_output()\n",
    "        \n",
    "        if not session_responses:\n",
    "            rprint(\"[yellow]No responses in session yet[/yellow]\")\n",
    "            return\n",
    "        \n",
    "        rprint(f\"[bold]Session Statistics[/bold] ({len(session_responses)} responses)\\n\")\n",
    "        \n",
    "        df = compare_responses(session_responses)\n",
    "        \n",
    "        total_tokens = df['total_tokens'].sum()\n",
    "        total_cost = df['estimated_cost'].sum()\n",
    "        avg_words = df['word_count'].mean()\n",
    "        \n",
    "        table = Table(title=\"Session Summary\")\n",
    "        table.add_column(\"Metric\", style=\"cyan\")\n",
    "        table.add_column(\"Value\", style=\"green\")\n",
    "        \n",
    "        table.add_row(\"Total Responses\", str(len(session_responses)))\n",
    "        table.add_row(\"Total Tokens\", str(total_tokens))\n",
    "        table.add_row(\"Total Cost\", f\"${total_cost:.6f}\")\n",
    "        table.add_row(\"Avg Words/Response\", f\"{avg_words:.1f}\")\n",
    "        table.add_row(\"Avg Cost/Response\", f\"${total_cost / len(session_responses):.6f}\")\n",
    "        \n",
    "        console.print(table)\n",
    "        \n",
    "        rprint(\"\\n[bold]Detailed Metrics:[/bold]\")\n",
    "        display(HTML(df.to_html()))\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        axes[0, 0].bar(df['response_id'], df['word_count'], color='skyblue')\n",
    "        axes[0, 0].set_title('Word Count by Response')\n",
    "        axes[0, 0].set_xlabel('Response')\n",
    "        axes[0, 0].set_ylabel('Words')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        axes[0, 1].bar(df['response_id'], df['total_tokens'], color='lightcoral')\n",
    "        axes[0, 1].set_title('Token Usage by Response')\n",
    "        axes[0, 1].set_xlabel('Response')\n",
    "        axes[0, 1].set_ylabel('Tokens')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        axes[1, 0].bar(df['response_id'], df['estimated_cost'], color='lightgreen')\n",
    "        axes[1, 0].set_title('Cost by Response')\n",
    "        axes[1, 0].set_xlabel('Response')\n",
    "        axes[1, 0].set_ylabel('Cost (USD)')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        cumulative_cost = df['estimated_cost'].cumsum()\n",
    "        axes[1, 1].plot(range(1, len(cumulative_cost) + 1), cumulative_cost, marker='o', color='purple')\n",
    "        axes[1, 1].set_title('Cumulative Cost Over Session')\n",
    "        axes[1, 1].set_xlabel('Response Number')\n",
    "        axes[1, 1].set_ylabel('Cumulative Cost (USD)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def on_export(b):\n",
    "    with analysis_output:\n",
    "        analysis_output.clear_output(wait=True)\n",
    "        \n",
    "        if not session_responses:\n",
    "            rprint(\"[yellow]No responses to export[/yellow]\")\n",
    "            return\n",
    "        \n",
    "        df = compare_responses(session_responses)\n",
    "        \n",
    "        filename = f\"session_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        \n",
    "        rprint(f\"[green]✓[/green] Results exported to {filename}\")\n",
    "\n",
    "def on_clear(b):\n",
    "    global session_responses\n",
    "    session_responses = []\n",
    "    with analysis_output:\n",
    "        analysis_output.clear_output()\n",
    "        rprint(\"[green]✓[/green] Session cleared\")\n",
    "\n",
    "analyze_button.on_click(on_analyze)\n",
    "export_button.on_click(on_export)\n",
    "clear_button.on_click(on_clear)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Results Analysis</h3>\"),\n",
    "    widgets.HBox([analyze_button, export_button, clear_button]),\n",
    "    analysis_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Info\n",
    "\n",
    "Quick view of current session status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(f\"[bold cyan]Current Configuration:[/bold cyan]\")\n",
    "rprint(f\"Model: {model_selector.value}\")\n",
    "rprint(f\"Temperature: {temperature_slider.value}\")\n",
    "rprint(f\"Max Tokens: {max_tokens_slider.value}\")\n",
    "rprint(f\"\\n[bold cyan]Session Status:[/bold cyan]\")\n",
    "rprint(f\"Responses: {len(session_responses)}\")\n",
    "if session_responses:\n",
    "    total_cost = sum(calculate_metrics(r)['estimated_cost'] for r in session_responses)\n",
    "    rprint(f\"Total Cost: ${total_cost:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
