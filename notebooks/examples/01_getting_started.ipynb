{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Prompt Engineering Playground\n",
    "\n",
    "This notebook will guide you through the basics of using the prompt engineering playground.\n",
    "\n",
    "## What You'll Learn\n",
    "- Setting up the Anthropic client\n",
    "- Sending your first prompt to Claude\n",
    "- Understanding the response structure\n",
    "- Basic parameter tuning for different use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_playground.client import create_client, send_prompt, count_tokens, estimate_cost\n",
    "from prompt_playground.analysis import calculate_metrics, analyze_tone\n",
    "from rich import print as rprint\n",
    "from rich.panel import Panel\n",
    "\n",
    "client = create_client()\n",
    "rprint(\"[green]✓[/green] Client initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Your First Prompt\n",
    "\n",
    "Let's start with a simple prompt. The `send_prompt()` function sends a prompt to Claude and returns a structured response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain what prompt engineering is in one sentence.\"\n",
    "\n",
    "response = send_prompt(\n",
    "    prompt=prompt,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "rprint(Panel(response['text'], title=\"[bold cyan]Claude's Response[/bold cyan]\", expand=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Response\n",
    "\n",
    "The response contains more than just text. Let's explore the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(\"\\n[bold]Response Structure:[/bold]\")\n",
    "rprint(f\"Text: {response['text'][:100]}...\")\n",
    "rprint(f\"Model: {response['model']}\")\n",
    "rprint(f\"Stop Reason: {response['stop_reason']}\")\n",
    "rprint(f\"Input Tokens: {response['input_tokens']}\")\n",
    "rprint(f\"Output Tokens: {response['output_tokens']}\")\n",
    "rprint(f\"Total Tokens: {response['total_tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Counting and Cost Estimation\n",
    "\n",
    "Understanding token usage helps you optimize costs and stay within limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tokens = count_tokens(prompt)\n",
    "rprint(f\"\\n[cyan]Prompt tokens:[/cyan] {prompt_tokens}\")\n",
    "\n",
    "cost_info = estimate_cost(\n",
    "    input_tokens=response['input_tokens'],\n",
    "    output_tokens=response['output_tokens'],\n",
    "    model=response['model']\n",
    ")\n",
    "\n",
    "rprint(f\"[cyan]Input cost:[/cyan] ${cost_info['input_cost']:.6f}\")\n",
    "rprint(f\"[cyan]Output cost:[/cyan] ${cost_info['output_cost']:.6f}\")\n",
    "rprint(f\"[cyan]Total cost:[/cyan] ${cost_info['total_cost']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning: Temperature\n",
    "\n",
    "Temperature controls randomness in responses:\n",
    "- **0.0**: Deterministic, focused responses\n",
    "- **0.5**: Balanced creativity and consistency\n",
    "- **1.0**: More creative and varied responses\n",
    "\n",
    "Let's compare different temperature settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_prompt = \"Write a creative tagline for a coffee shop.\"\n",
    "\n",
    "temperatures = [0.0, 0.5, 1.0]\n",
    "\n",
    "for temp in temperatures:\n",
    "    response = send_prompt(\n",
    "        prompt=creative_prompt,\n",
    "        temperature=temp,\n",
    "        client=client\n",
    "    )\n",
    "    rprint(f\"\\n[bold cyan]Temperature {temp}:[/bold cyan]\")\n",
    "    rprint(response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning: Max Tokens\n",
    "\n",
    "`max_tokens` controls the maximum length of the response. Use it to:\n",
    "- Limit response length for concise answers\n",
    "- Allow longer responses for detailed explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain quantum computing.\"\n",
    "\n",
    "short_response = send_prompt(\n",
    "    prompt=prompt,\n",
    "    max_tokens=100,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "long_response = send_prompt(\n",
    "    prompt=prompt,\n",
    "    max_tokens=500,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "rprint(\"\\n[bold cyan]Short Response (100 tokens):[/bold cyan]\")\n",
    "rprint(Panel(short_response['text'], expand=False))\n",
    "rprint(f\"Actual tokens: {short_response['output_tokens']}\")\n",
    "\n",
    "rprint(\"\\n[bold cyan]Long Response (500 tokens):[/bold cyan]\")\n",
    "rprint(Panel(long_response['text'], expand=False))\n",
    "rprint(f\"Actual tokens: {long_response['output_tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using System Prompts\n",
    "\n",
    "System prompts set the context and behavior for Claude. They're useful for:\n",
    "- Defining roles or personas\n",
    "- Setting output formats\n",
    "- Establishing guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = send_prompt(\n",
    "    prompt=\"Explain recursion.\",\n",
    "    system=\"You are a computer science teacher explaining concepts to beginners. Use simple language and analogies.\",\n",
    "    client=client\n",
    ")\n",
    "\n",
    "rprint(Panel(response['text'], title=\"[bold]Response with System Prompt[/bold]\", expand=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Analysis\n",
    "\n",
    "Use the analysis tools to understand response characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_metrics(response)\n",
    "\n",
    "rprint(\"\\n[bold]Response Metrics:[/bold]\")\n",
    "rprint(f\"Words: {metrics['word_count']}\")\n",
    "rprint(f\"Characters: {metrics['char_count']}\")\n",
    "rprint(f\"Sentences: {metrics['sentence_count']}\")\n",
    "rprint(f\"Paragraphs: {metrics['paragraph_count']}\")\n",
    "rprint(f\"Avg sentence length: {metrics['avg_sentence_length']} words\")\n",
    "\n",
    "tone = analyze_tone(response['text'])\n",
    "rprint(f\"\\n[bold]Tone Analysis:[/bold]\")\n",
    "rprint(f\"Formality: {tone['formality']}\")\n",
    "rprint(f\"Complexity: {tone['complexity']}\")\n",
    "rprint(f\"Perspective: {tone['perspective']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### 1. Be Specific\n",
    "Clear, specific prompts yield better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vague_prompt = \"Tell me about dogs.\"\n",
    "specific_prompt = \"List 5 key differences between Golden Retrievers and Labrador Retrievers in terms of temperament and care requirements.\"\n",
    "\n",
    "response = send_prompt(prompt=specific_prompt, client=client)\n",
    "rprint(Panel(response['text'], title=\"[bold green]Specific Prompt Result[/bold green]\", expand=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use Examples (Few-Shot Learning)\n",
    "Provide examples to guide the response format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\"Convert these product names to URL slugs:\n",
    "\n",
    "Product: \"Super Comfort Running Shoes\"\n",
    "Slug: super-comfort-running-shoes\n",
    "\n",
    "Product: \"Professional Gaming Mouse\"\n",
    "Slug: professional-gaming-mouse\n",
    "\n",
    "Product: \"Wireless Noise-Canceling Headphones XM5\"\n",
    "Slug: \"\"\"\n",
    "\n",
    "response = send_prompt(prompt=few_shot_prompt, temperature=0.0, client=client)\n",
    "rprint(f\"[bold cyan]Generated slug:[/bold cyan] {response['text'].strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Iterate and Refine\n",
    "Test different variations and refine based on results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Summarize this: Artificial intelligence is transforming industries.\",\n",
    "    \"In one sentence, summarize: Artificial intelligence is transforming industries.\",\n",
    "    \"Create a 10-word summary: Artificial intelligence is transforming industries.\"\n",
    "]\n",
    "\n",
    "for i, p in enumerate(prompts, 1):\n",
    "    response = send_prompt(prompt=p, client=client)\n",
    "    rprint(f\"\\n[cyan]Version {i}:[/cyan] {response['text']}\")\n",
    "    rprint(f\"  Words: {len(response['text'].split())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you understand the basics, explore:\n",
    "- **02_prompt_templates.ipynb**: Create reusable prompt templates\n",
    "- **03_ab_testing.ipynb**: Compare different prompt variations\n",
    "- **04_batch_processing.ipynb**: Process multiple prompts efficiently\n",
    "- **05_evaluation_metrics.ipynb**: Define custom quality metrics\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "- ✓ How to set up and use the client\n",
    "- ✓ Understanding response structure and metrics\n",
    "- ✓ Parameter tuning (temperature, max_tokens)\n",
    "- ✓ Using system prompts effectively\n",
    "- ✓ Best practices for prompt engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
